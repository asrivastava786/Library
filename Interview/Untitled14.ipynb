{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jadwiga Bilecka 01.01.1978\n",
      "Rafal Bobek 11.04.1978\n",
      "Robert Bobekowski 20.07.1978\n",
      "Rafal Bobikowski 28.10.1978\n",
      "Rafal Brobek 5.02.1979\n",
      "Wiktor Brudziak 16.05.1979\n",
      "Boleslaw Brynski 24.08.1979\n",
      "Jadwiga Chrilecka 2.12.1979\n",
      "Liliana Ciupala 11.03.1980\n",
      "Katarzyna Dawro 19.06.1980\n",
      "Jadwiga Derilecka 27.09.1980\n",
      "Michal Dertucha 5.01.1981\n",
      "Robert Dido 15.04.1981\n",
      "Michal Dindo 24.07.1981\n",
      "Rafal Dobek 1.11.1981\n",
      "Andrzej Drozda 9.02.1982\n",
      "Wiktor Dudziak 20.05.1982\n",
      "Robert Dwernik 28.08.1982\n",
      "Michal Fadecki 6.12.1982\n",
      "Barbara Fibiana 16.03.1983\n",
      "Jadwiga Filbrecka 24.06.1983\n",
      "Kalina Filecka 2.10.1983\n",
      "Jolanta Filecka 10.01.1984\n",
      "Jadwiga Filoecka 19.04.1984\n",
      "Jadwiga Firlecka 28.07.1984\n",
      "Rafal Forbek 5.11.1984\n",
      "Barbara Fornal 13.02.1985\n",
      "Rafal Fraczynski 24.05.1985\n",
      "Jadwiga Fulecka 1.09.1985\n",
      "Jadwiga Gilecka 10.12.1985\n",
      "Rafal Grater 20.03.1986\n",
      "Zbigniew Grawik 28.06.1986\n",
      "Pelagia Greczyn 6.10.1986\n",
      "Barbara Griczan 14.01.1987\n",
      "Barbara Gruda 24.04.1987\n",
      "Zbigniew Hrubek 2.08.1987\n",
      "Wiktor Hryczynski 10.11.1987\n",
      "Andrzej Jadziak 18.02.1988\n",
      "Barbara Jagiel 28.05.1988\n",
      "Stefan Janicki 5.09.1988\n",
      "Robert Jawlik 14.12.1988\n",
      "Barbara Jelikowska 24.03.1989\n",
      "Wiktor Jobda 2.07.1989\n",
      "Jadwiga Jolecka 10.10.1989\n",
      "Wiktor Karolik 18.01.1990\n",
      "Zbigniew Kakol 28.04.1990\n",
      "Barbara Kiszewska 6.08.1990\n",
      "Rafal Kobek 14.11.1990\n",
      "Tadeusz Komasa 22.02.1991\n",
      "Michal Komor 2.06.1991\n",
      "Tadeusz Komorak 10.09.1991\n",
      "Tadeusz Komorna 19.12.1991\n",
      "Michal Komornicki 28.03.1992\n",
      "Tadeusz Komornikow 6.07.1992\n",
      "Michal Komos 14.10.1992\n",
      "Tadeusz Kowalski 22.01.1993\n",
      "Wiktor Krupicki 2.05.1993\n",
      "Janusz Kurant 10.08.1993\n",
      "Michal Kureka 18.11.1993\n",
      "Wiktor Labuda 26.02.1994\n",
      "Zbigniew Liczaba 6.06.1994\n",
      "Robert Liczak 14.09.1994\n",
      "Michal Likary 23.12.1994\n",
      "Mateusz Likian 2.04.1995\n",
      "Marek Linda 11.07.1995\n",
      "Michal Lindak 19.10.1995\n",
      "Franciszek Lindarek 27.01.1996\n",
      "Michal Lipecki 6.05.1996\n",
      "Ewa Masztaler 14.08.1996\n",
      "Barbara Maczynska 22.11.1996\n",
      "Zbigniew Makol 2.03.1997\n",
      "Jadwiga Milecka 10.06.1997\n",
      "Robert Moczydlo 18.09.1997\n",
      "Ewa Niemota 27.12.1997\n",
      "Robert Palancik 6.04.1998\n",
      "Pawel Palek 15.07.1998\n",
      "Krystyna Pilecki 23.10.1998\n",
      "Krystyna Policka 31.01.1999\n",
      "Krzysztof Policki 11.05.1999\n",
      "Elwira Policzawska 19.08.1999\n",
      "Pawel Policzewski 27.11.1999\n",
      "Krystyna Polkowiak 6.03.2000\n",
      "Wiktor Proszak 14.06.2000\n",
      "Andrzej Robek 22.09.2000\n",
      "Zbigniew Rudak 31.12.2000\n",
      "Barbara Sadurski 10.04.2001\n",
      "Marek Sawek 19.07.2001\n",
      "Robert Sulik 27.10.2001\n",
      "Zbigniew Sulik 4.02.2002\n",
      "Robert Sulikowski 15.05.2002\n",
      "Robert Surma 23.08.2002\n",
      "Robert Surmak 1.12.2002\n",
      "Wiktor Suwald 11.03.2003\n",
      "Michal Szerka 19.06.2003\n",
      "Tadeusz Tomora 27.09.2003\n",
      "Zbigniew Trewirek 5.01.2004\n",
      "Zbigniew Twardzioch 14.04.2004\n",
      "Andrzej Twarnowski 23.07.2004\n",
      "Tadeusz Twomicki 31.10.2004\n",
      "Michal Wertyk 8.02.2005\n",
      "Rafal Wobek 19.05.2005\n",
      "Tadeusz Womor 27.08.2005\n",
      "Robert Wyszon 5.12.2005\n",
      "Robert Zamek 15.03.2006\n",
      "Wiktor Zamlcki 23.06.2006\n",
      "Tadeusz Zomornik 1.10.2006\n",
      "Edward Zeligowski 9.01.2007\n",
      "Zbigniew Zeligowski 19.04.2007\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "items= []\n",
    "with open('zadanie1.csv', newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:        \n",
    "        print(row['imie'], row['nazwisko'], row['data_urodzenia'])\n",
    "        items.append(row)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "born_later = []\n",
    "female_name = []\n",
    "date = datetime.strptime('31.12.1999', '%d.%m.%Y')\n",
    "\n",
    "for row in items:\n",
    "    if datetime.strptime(row['data_urodzenia'], '%d.%m.%Y') > date:\n",
    "        born_later.append(row)\n",
    "    \n",
    "    if row['imie'][-1] == 'a':\n",
    "        female_name.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_list_femaleNames = list({v['imie'] and v['nazwisko']:v for v in female_name}.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "print(len(female_name))\n",
    "print(len(distinct_list_femaleNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flickrapi\n",
      "  Downloading flickrapi-2.4.0-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from flickrapi) (1.12.0)\n",
      "Requirement already satisfied: requests>=2.2.1 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from flickrapi) (2.22.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.4.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from flickrapi) (1.3.0)\n",
      "Collecting requests-toolbelt>=0.3.1\n",
      "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from requests>=2.2.1->flickrapi) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from requests>=2.2.1->flickrapi) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from requests>=2.2.1->flickrapi) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from requests>=2.2.1->flickrapi) (1.24.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.4.0->flickrapi) (3.1.0)\n",
      "Installing collected packages: requests-toolbelt, flickrapi\n",
      "Successfully installed flickrapi-2.4.0 requests-toolbelt-0.9.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install flickrapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flickrapi import FlickrAPI\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = '453b069b2a5b47a479a944f94ddc548e'\n",
    "SECRET = '931e81170b208eee'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(image_tag ,MAX_COUNT = 100):\n",
    "    \n",
    "    flickr = FlickrAPI(KEY, SECRET)\n",
    "    photos = flickr.walk(text=image_tag,\n",
    "                            tag_mode='all',\n",
    "                            tags=image_tag,\n",
    "                            extras='url_o',\n",
    "                            per_page=50,\n",
    "                            sort='relevance')\n",
    "    count=0\n",
    "    urls=[]\n",
    "    \n",
    "    for photo in photos:\n",
    "        if count < MAX_COUNT:           \n",
    "            print(\"Fetching url for image number {}\".format(count))\n",
    "            try:\n",
    "                url=photo.get('url_o')\n",
    "                if url:\n",
    "                    urls.append(url)\n",
    "                    count=count+1\n",
    "            except:\n",
    "                print(\"Url for image number {} could not be fetched\".format(count))\n",
    "        else:\n",
    "            print(\"Done fetching urls, fetched {} urls out of {}\".format(len(urls),MAX_COUNT))\n",
    "            break\n",
    "    urls=pd.Series(urls)\n",
    "    print(\"Writing out the urls in the current directory\")\n",
    "    urls.to_csv(image_tag+\"_urls.csv\")\n",
    "    print(\"Done!!!\")\n",
    "    return image_tag+\"_urls.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching url for image number 0\n",
      "Fetching url for image number 0\n",
      "Fetching url for image number 0\n",
      "Fetching url for image number 1\n",
      "Fetching url for image number 2\n",
      "Fetching url for image number 2\n",
      "Fetching url for image number 2\n",
      "Fetching url for image number 3\n",
      "Fetching url for image number 3\n",
      "Fetching url for image number 3\n",
      "Fetching url for image number 3\n",
      "Fetching url for image number 4\n",
      "Fetching url for image number 5\n",
      "Fetching url for image number 5\n",
      "Fetching url for image number 6\n",
      "Fetching url for image number 6\n",
      "Fetching url for image number 6\n",
      "Fetching url for image number 6\n",
      "Fetching url for image number 6\n",
      "Fetching url for image number 6\n",
      "Fetching url for image number 7\n",
      "Fetching url for image number 8\n",
      "Fetching url for image number 8\n",
      "Fetching url for image number 8\n",
      "Fetching url for image number 8\n",
      "Fetching url for image number 8\n",
      "Fetching url for image number 9\n",
      "Done fetching urls, fetched 10 urls out of 10\n",
      "Writing out the urls in the current directory\n",
      "Done!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akash\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "f = get_urls('cat', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "def put_images(FILE_NAME):\n",
    "    urls=[]\n",
    "    with open(FILE_NAME,newline=\"\") as csvfile:\n",
    "        doc=csv.reader(csvfile,delimiter=\",\")\n",
    "        for row in doc:\n",
    "            if row[1].startswith(\"https\"):\n",
    "                urls.append(row[1])\n",
    "    if not os.path.isdir(os.path.join(os.getcwd(),FILE_NAME.split(\"_\")[0])):\n",
    "        os.mkdir(FILE_NAME.split(\"_\")[0])\n",
    "    t0=time.time()\n",
    "    for url in enumerate(urls):\n",
    "        print(\"Starting download {} of \".format(url[0]+1),len(urls))\n",
    "        try:\n",
    "            resp=requests.get(url[1],stream=True)\n",
    "            path_to_write=os.path.join(os.getcwd(),FILE_NAME.split(\"_\")[0],url[1].split(\"/\")[-1])\n",
    "            outfile=open(path_to_write,'wb')\n",
    "            outfile.write(resp.content)\n",
    "            outfile.close()\n",
    "            print(\"Done downloading {} of {}\".format(url[0]+1,len(urls)))\n",
    "        except:\n",
    "            print(\"Failed to download url number {}\".format(url[0]))\n",
    "    t1=time.time()\n",
    "    print(\"Done with download, job took {} seconds\".format(t1-t0))\n",
    "    return os.path.join(os.getcwd(),FILE_NAME.split(\"_\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download 1 of  10\n",
      "Done downloading 1 of 10\n",
      "Starting download 2 of  10\n",
      "Done downloading 2 of 10\n",
      "Starting download 3 of  10\n",
      "Done downloading 3 of 10\n",
      "Starting download 4 of  10\n",
      "Done downloading 4 of 10\n",
      "Starting download 5 of  10\n",
      "Done downloading 5 of 10\n",
      "Starting download 6 of  10\n",
      "Done downloading 6 of 10\n",
      "Starting download 7 of  10\n",
      "Done downloading 7 of 10\n",
      "Starting download 8 of  10\n",
      "Done downloading 8 of 10\n",
      "Starting download 9 of  10\n",
      "Done downloading 9 of 10\n",
      "Starting download 10 of  10\n",
      "Done downloading 10 of 10\n",
      "Done with download, job took 7.255508661270142 seconds\n"
     ]
    }
   ],
   "source": [
    "path = put_images(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Akash\\\\cat'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "def get_red_pixcel(path):\n",
    "    \n",
    "    onlyfiles = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    count = 1\n",
    "\n",
    "    for image in onlyfiles:\n",
    "        img = cv2.imread(path + '\\\\' + image)\n",
    "        print(path + '\\\\' + image)\n",
    "        #red_px_value = img[100,100]\n",
    "        red_px_value = img[100,100,0]\n",
    "        count = count +1 \n",
    "        \n",
    "        #Connecting to sqlite\n",
    "        conn = sqlite3.connect('example.db')\n",
    "\n",
    "        #Creating a cursor object using the cursor() method\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "\n",
    "        cursor.execute(\"INSERT INTO Image1(ID, path, color) VALUES(?, ?, ?)\",(count, image, red_px_value))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table created successfully........\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "#Connecting to sqlite\n",
    "conn = sqlite3.connect('example.db')\n",
    "\n",
    "#Creating a cursor object using the cursor() method\n",
    "cursor = conn.cursor()\n",
    "\n",
    "#Doping EMPLOYEE table if already exists.\n",
    "cursor.execute(\"DROP TABLE IF EXISTS Image1\")\n",
    "\n",
    "#Creating table as per requirement\n",
    "sql ='''CREATE TABLE Image1(\n",
    "   ID CHAR(20) NOT NULL Primary key,\n",
    "   Path char(80),\n",
    "   Color CHAR\n",
    ")'''\n",
    "cursor.execute(sql)\n",
    "print(\"Table created successfully........\")\n",
    "\n",
    "# Commit your changes in the database\n",
    "conn.commit()\n",
    "\n",
    "#Closing the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akash\\cat\\11991979753_2fca5eae56_o.jpg\n",
      "C:\\Users\\Akash\\cat\\25690386427_2002fb09a7_o.jpg\n",
      "C:\\Users\\Akash\\cat\\39256672581_31c0ab53f0_o.jpg\n",
      "C:\\Users\\Akash\\cat\\41676479745_7f27fda0c0_o.jpg\n",
      "C:\\Users\\Akash\\cat\\4638426067_90c4df41e9_o.jpg\n",
      "C:\\Users\\Akash\\cat\\46550224945_0933c0422d_o.jpg\n",
      "C:\\Users\\Akash\\cat\\5508784414_3ec3992ddc_o.jpg\n",
      "C:\\Users\\Akash\\cat\\6581178955_2817bf99b0_o.jpg\n",
      "C:\\Users\\Akash\\cat\\7190755946_8b6c33e000_o.jpg\n",
      "C:\\Users\\Akash\\cat\\8243537591_44c4a45644_o.jpg\n"
     ]
    }
   ],
   "source": [
    "get_red_pixcel(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#sqllite \n",
    "conn = sqlite3.connect('example.db')\n",
    "\n",
    "#Creating a cursor object using the cursor() method\n",
    "cursor = conn.cursor()\n",
    "\n",
    "#Retrieving data\n",
    "cursor.execute('''SELECT * FROM Image1 ''')\n",
    "\n",
    "#Fetching 1st row from the table\n",
    "result = cursor.fetchone();\n",
    "print(result)\n",
    "\n",
    "#Fetching 1st row from the table\n",
    "result = cursor.fetchall();\n",
    "print(result)\n",
    "\n",
    "#Commit your changes in the database\n",
    "conn.commit()\n",
    "\n",
    "#Closing the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
